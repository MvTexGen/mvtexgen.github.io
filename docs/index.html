
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
    width: 980px;
}
h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #1367a7;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1, h2, h3 {
    text-align: center;
}
h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
.paper-title {
    padding: 16px 0px 16px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-6 {
     width: 16.6%;
     float: left;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.row, .author-row, .affil-row {
     overflow: auto;
}
.author-row, .affil-row {
    font-size: 20px;
}
.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 18px;
}
.affil-row {
    margin-top: 16px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: left;
    margin-top: 8px;
    margin-bottom: 8px;
}
video {
    display: block;
    margin: auto;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    justify-content: space-around;
    padding: 0;
    margin: 0;
    list-style: none;
}
.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #1367a7;
  color: #ecf0f1 !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}

.supp-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #1367a7;
  color: #ecf0f1 !important;
  font-size: 20px;
  width: 150px;
  font-weight: 600;
}

.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}
.paper-btn:hover {
    opacity: 0.85;
}
.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}
.venue {
    color: #1367a7;
}



.topnav {
  overflow: hidden;
  background-color: #EEEEEE;
}

.topnav a {
  float: left;
  color: black;
  text-align: center;
  padding: 14px 16px;
  text-decoration: none;
  font-size: 16px;
}



</style>


<div class="topnav" id="myTopnav">
  <a href="https://www.shlab.org.cn/"><img width="30%" src="assets/pjlab.png"></a>
  <a href="https://www.shlab.org.cn/" ><strong>Shanghai AI Laboratory</strong></a>
</div>

<!-- End : Google Analytics Code -->
<script type="text/javascript" src="../js/hidebib.js"></script>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
<head>
    <title>MVTexGen: Synthesising 3D Textures Using Multi-View Diffusion</title>
    <meta property="og:description" content="MVTexGen: Synthesising 3D Textures Using Multi-View Diffusion"/>
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">

</head>


 <body>
<div class="container">
    <div class="paper-title">
      <h1>MVTexGen: Synthesising 3D Textures Using Multi-View Diffusion</h1>
    </div>

    
    <div id="authors">
        <div class="author-row">
            <div class="col-3 text-center"><a href="https://scholar.google.com/citations?user=M0xVv3cAAAAJ&hl=en">Jinyi Wang</a><sup>1</sup></div>
            <div class="col-3 text-center"><a href="">Ben Fei</a><sup>*1,2</sup></div>
            <div class="col-3 text-center"><a href="">Huangjie Zheng</a><sup>1,4</sup></div>
            <div class="col-3 text-center"><a href="">Jiangchao Yao</a><sup>1,4</sup></div>
            <div class="col-3 text-center"><a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a><sup>1,4</sup></div>
            <div class="col-3 text-center"><a href="">Yanfeng Wang</a><sup>1,4</sup></div>
        </div>

        <div class="affil-row">
            <div class="col-4 text-center"><sup>1</sup>Shanghai Jiatong University</a></div>
            <div class="col-4 text-center"><sup>2</sup>Fudan University</div>
            <div class="col-4 text-center"><sup>3</sup>University of Texas at Austin</div>
            <div class="col-4 text-center"><sup>4</sup>Shanghai AI Laboratory</div>
        </div>
        <div class="affil-row">
            <div class="venue text-center"><b>CVPR 2023</b></div>
        </div>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="supp-btn" href="https://arxiv.org/abs/2303.07938">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
            <a class="supp-btn" href="assets/appendix.pdf">
                <span class="material-icons"> description </span> 
                    Appendix
            </a>

            <a class="supp-btn" href="assets/bib.txt">
                <span class="material-icons"> description </span> 
                  BibTeX
            </a>
            <a class="supp-btn" href="https://github.com/SLIDE-3D/SLIDE.git">
                <span class="material-icons"> description </span> 
                  Code
            </a>
        </div></div>
    </div>

    <section id="teaser">
            <figure style="width: 100%;">
                <a href="assets/Figs-Pipeline.png">
                    <img width="100%" src="assets/Figs-Pipeline.png">
                </a>
                <p class="caption" style="margin-bottom: 1px;  text-align: justify">
                    The autoencoder that encodes a mesh to features at the sparse latent points and decode it back to a mesh.
                </p>
            </figure>
            <br>
            <figure style="width: 100%;">
             <video class="centered" width="90%" controls muted loop autoplay>
                <source src="assets/mesh_rotate.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p class="caption" style="margin-bottom : 1px; text-align: justify">
                SLIDE can generate meshes with different shapes. 
            </p>
        </figure>
    </section>

    <section id="abstract"/>
        <h2>Abstract</h2>
        <hr>
        <p>
            Mesh generation is of great value in various applications involving computer graphics and virtual content, 
            yet designing generative models for meshes is challenging due to their irregular data structure and inconsistent topology of meshes in the same category.
            In this work, we design a novel sparse latent point diffusion model for mesh generation.
            Our key insight is to regard point clouds as an intermediate representation of meshes,
            and model the distribution of point clouds instead.
            While meshes can be generated from point clouds via techniques like Shape as Points (SAP),
            the challenges of directly generating meshes can be effectively avoided.
            To boost the efficiency and controlability of our mesh generation method,
            we propose to further encode point clouds to a set of sparse latent points with point-wise semantic meaningful features,
            where two DDPMs are trained in the space of sparse latent points to respectively model the distribution of the latent point positions and features at these latent points.
            We find that sampling in this latent space is faster than directly sampling dense point clouds.
            Moreover,
            the sparse latent points also enable us to explicitly control both the overall structures and local details of the generated meshes.
            Extensive experiments are conducted on the ShapeNet dataset, where our proposed sparse latent point diffusion model achieves superior performance in terms of generation quality and controlability when compared to existing methods.
            </p>
    </section>

    <section id="paper">
        <h2>Paper</h2>
        <hr>
        <div class="flex-row">
            <div style="box-sizing: border-box; padding: 16px; margin: auto;">
                <a href="assets/paper.pdf"><img class="screenshot" src="assets/SLIDE_paper_figure.png"></a>
            </div>
            <div style="width: 50%">
                <p><b>MVTexGen: Synthesising 3D Textures Using Multi-View Diffusion</b></p>
                <p>Zhaoyang Lyu*, Jinyi Wang*, Yuwei An, Ya Zhang, Dahua Lin, Bo Dai</p>
                <div><span class="material-icons"> description </span><a href="assets/paper.pdf"> PDF</a></div>
                <div><span class="material-icons"> description </span><a href="assets/appendix.pdf"> Appendix</a></div>
                <div><span class="material-icons"> description </span><a href="https://arxiv.org/abs/2303.07938"> arXiv version</a></div>
                <div><span class="material-icons"> insert_comment </span><a href="assets/bib.txt"> BibTeX</a></div>
            </div>
        </div>
    </section>


    <section id="results">

        <h2>Generated 3D Assets</h2>
        <hr>

        <figure style="width: 100%;">
             <video class="centered" width="90%" controls muted loop autoplay>
                <source src="assets/mesh_kps_rotate.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p class="caption" style="margin-bottom: 1px; text-align: justify">
                Meshes and corresponding points and sparse latent points generated by SLIDE with different shapes.

            </p>
        </figure>


        <h2>Movement of sparse latent points to control generated mesh</h2>
        <hr>

        <figure style="width: 100%;">
             <video class="centered" width="90%" controls muted loop autoplay>
                <source src="assets/move_chair.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p class="caption" style="margin-bottom: 1px; text-align: justify;">
                Through moving the two points of chair legs to control the position of chair legs.
                </p>
        </figure>

        <h2>Interpolation of two different lamps</h2>
        <hr>

        <figure style="width: 100%;">
             <video class="centered" width="90%" controls muted loop autoplay>
                <source src="assets/interpolation_lamp.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p class="caption" style="margin-bottom: 1px; text-align: justify;">
                Give two lamps, we get the interpolation results of two lamps by interpolating the sparse latent points.
                </p>
        </figure>


        <h2>Interpolating upper part of two different lamps</h2>
        <hr>
        <figure style="width: 100%;">
             <video class="centered" width="90%" controls muted loop autoplay>
                <source src="assets/top_interpolation_lamp.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p class="caption" style="margin-bottom: 1px; text-align: justify;">
                Give two lamps, we only interpolate the upper part of two lamps by interpolating the sparse latent points.
                </p>
        </figure>


        <h2>Merge two shapes by combining part sparse latent points</h2>
        <hr>
        <figure style="width: 100%;">
             <video class="centered" width="90%" controls muted loop autoplay>
                <source src="assets/merge_lamp.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p class="caption" style="margin-bottom: 1px; text-align: justify;">
                Combining the sparse latent points of two lamps to generate a new lamp.
                </p>
        </figure>

        <h2>Compare of two generation results of moving keypoints: Fixing rest & Global change</h2>
        <hr>
        <figure style="width: 100%;">
             <video class="centered" width="90%" controls muted loop autoplay>
                <source src="assets/two_compare.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p class="caption" style="margin-bottom: 1px; text-align: justify;">
                Move the two points of chair legs to control the position of chair legs. Orange chairs represent the results of fixing the rest of the mesh and green chairs represent the results of global change.
                </p>
        </figure>

        <h2>More examples</h2>
        <hr>
        <figure style="width: 100%;">
            <img class="centered" src="assets/slide_more_examples_demo.png" width="90%">
            <p class="caption" style="margin-bottom: 1px; text-align: justify;">
                More examples of SLIDE generation results.
                </p>
        </figure>


    </section>
    

    <section id="bibtex">
        <h2>Citation</h2>
        <hr>

        <pre><code>
            @misc{https://doi.org/10.48550/arxiv.2303.07938,
                doi = {10.48550/ARXIV.2303.07938},
                
                url = {https://arxiv.org/abs/2303.07938},
                
                author = {Lyu, Zhaoyang and Wang, Jinyi and An, Yuwei and Zhang, Ya and Lin, Dahua and Dai, Bo},
                
                keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
                
                title = {Controllable Mesh Generation Through Sparse Latent Point Diffusion Models},
                
                publisher = {arXiv},
                
                year = {2023},
                
                copyright = {Creative Commons Attribution 4.0 International}
              }
              
        </code></pre>
    </section>



<br />
    

</div>
</body>
</html>
